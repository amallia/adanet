

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>adanet.core.estimator &mdash; adanet [0.4.0] documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> adanet
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../adanet.html">adanet</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">adanet</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>adanet.core.estimator</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for adanet.core.estimator</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;An AdaNet estimator implementation in Tensorflow using a single graph.</span>

<span class="sd">Copyright 2018 The AdaNet Authors. All Rights Reserved.</span>

<span class="sd">Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="sd">you may not use this file except in compliance with the License.</span>
<span class="sd">You may obtain a copy of the License at</span>

<span class="sd">    https://www.apache.org/licenses/LICENSE-2.0</span>

<span class="sd">Unless required by applicable law or agreed to in writing, software</span>
<span class="sd">distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="sd">WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="sd">See the License for the specific language governing permissions and</span>
<span class="sd">limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">contextlib</span>
<span class="kn">import</span> <span class="nn">errno</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">from</span> <span class="nn">adanet.core.candidate</span> <span class="k">import</span> <span class="n">_CandidateBuilder</span>
<span class="kn">from</span> <span class="nn">adanet.core.ensemble</span> <span class="k">import</span> <span class="n">_EnsembleBuilder</span>
<span class="kn">from</span> <span class="nn">adanet.core.ensemble</span> <span class="k">import</span> <span class="n">MixtureWeightType</span>
<span class="kn">from</span> <span class="nn">adanet.core.iteration</span> <span class="k">import</span> <span class="n">_IterationBuilder</span>
<span class="kn">from</span> <span class="nn">adanet.core.report_accessor</span> <span class="k">import</span> <span class="n">_ReportAccessor</span>
<span class="kn">from</span> <span class="nn">adanet.core.summary</span> <span class="k">import</span> <span class="n">_ScopedSummary</span>
<span class="kn">from</span> <span class="nn">adanet.core.timer</span> <span class="k">import</span> <span class="n">_CountDownTimer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">six</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>


<span class="k">class</span> <span class="nc">_StopAfterTrainingHook</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SessionRunHook</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Hook that requests stop once iteration is over.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteration</span><span class="p">,</span> <span class="n">after_fn</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes a `_StopAfterTrainingHook`.</span>

<span class="sd">    Args:</span>
<span class="sd">      iteration: An `_Iteration` instance.</span>
<span class="sd">      after_fn: A function to call after training stopped.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `_StopAfterTrainingHook` instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_iteration</span> <span class="o">=</span> <span class="n">iteration</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_after_fn</span> <span class="o">=</span> <span class="n">after_fn</span>

  <span class="k">def</span> <span class="nf">before_run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;See `SessionRunHook`.&quot;&quot;&quot;</span>

    <span class="k">del</span> <span class="n">run_context</span>  <span class="c1"># Unused</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SessionRunArgs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_iteration</span><span class="o">.</span><span class="n">is_over_fn</span><span class="p">())</span>

  <span class="k">def</span> <span class="nf">after_run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">,</span> <span class="n">run_values</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;See `SessionRunHook`.&quot;&quot;&quot;</span>

    <span class="n">is_over</span> <span class="o">=</span> <span class="n">run_values</span><span class="o">.</span><span class="n">results</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_over</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="n">run_context</span><span class="o">.</span><span class="n">request_stop</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_after_fn</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">_EvalMetricSaverHook</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SessionRunHook</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A hook for writing evaluation metrics as summaries to disk.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">eval_metric_ops</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes a `_EvalMetricSaverHook` instance.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: String name of candidate owner of these metrics.</span>
<span class="sd">      eval_metric_ops: Dict of metric results keyed by name. The values of the</span>
<span class="sd">        dict are the results of calling a metric function, namely a</span>
<span class="sd">        `(metric_tensor, update_op)` tuple. `metric_tensor` should be evaluated</span>
<span class="sd">        without any impact on state (typically is a pure computation based on</span>
<span class="sd">        variables.). For example, it should not trigger the `update_op` or</span>
<span class="sd">        require any input fetching.</span>
<span class="sd">      output_dir: Directory for writing evaluation summaries.</span>

<span class="sd">    Returns:</span>
<span class="sd">      An `_EvalMetricSaverHook` instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_eval_metric_ops</span> <span class="o">=</span> <span class="n">eval_metric_ops</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_output_dir</span> <span class="o">=</span> <span class="n">output_dir</span>

  <span class="k">def</span> <span class="nf">before_run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">run_context</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;See `SessionRunHook`.&quot;&quot;&quot;</span>

    <span class="k">del</span> <span class="n">run_context</span>  <span class="c1"># Unused</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SessionRunArgs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_eval_metric_ops</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_dict_to_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get a `str` representation of a `dict`.</span>

<span class="sd">    Args:</span>
<span class="sd">      dictionary: The `dict` to be represented as `str`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `str` representing the `dictionary`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dictionary</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>

  <span class="k">def</span> <span class="nf">end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">session</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;See `SessionRunHook`.&quot;&quot;&quot;</span>

    <span class="c1"># Forked from tensorflow/python/estimator/estimator.py function called</span>
    <span class="c1"># _write_dict_to_summary.</span>
    <span class="n">eval_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_metric_ops</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">eval_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">current_global_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_global_step</span><span class="p">()</span>

    <span class="n">eval_dict</span><span class="p">,</span> <span class="n">current_global_step</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">((</span><span class="n">eval_dict</span><span class="p">,</span>
                                                  <span class="n">current_global_step</span><span class="p">))</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Saving candidate &#39;</span><span class="si">%s</span><span class="s2">&#39; dict for global step </span><span class="si">%d</span><span class="s2">: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="n">current_global_step</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_dict_to_str</span><span class="p">(</span><span class="n">eval_dict</span><span class="p">))</span>
    <span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriterCache</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_output_dir</span><span class="p">)</span>
    <span class="n">summary_proto</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">Summary</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">eval_dict</span><span class="p">:</span>
      <span class="n">value</span> <span class="o">=</span> <span class="n">eval_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
        <span class="n">summary_proto</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="n">key</span><span class="p">,</span> <span class="n">simple_value</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">binary_type</span><span class="p">):</span>
        <span class="n">summ</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">Summary</span><span class="o">.</span><span class="n">FromString</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">summ</span><span class="o">.</span><span class="n">value</span><span class="p">):</span>
          <span class="n">summ</span><span class="o">.</span><span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">tag</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/</span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">summary_proto</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">summ</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;Skipping summary for </span><span class="si">%s</span><span class="s2">, must be a float, np.float32, &quot;</span>
            <span class="s2">&quot;or a serialized string of Summary.&quot;</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>
    <span class="n">summary_writer</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">summary_proto</span><span class="p">,</span> <span class="n">current_global_step</span><span class="p">)</span>
    <span class="n">summary_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>


<div class="viewcode-block" id="Estimator"><a class="viewcode-back" href="../../../adanet.html#adanet.Estimator">[docs]</a><span class="k">class</span> <span class="nc">Estimator</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">Estimator</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;The AdaNet algorithm implemented with the `tf.estimator.Estimator` API.</span>

<span class="sd">  AdaNet is as defined in the paper: https://arxiv.org/abs/1607.01097.</span>

<span class="sd">  The AdaNet algorithm uses a weak learning algorithm to iteratively generate a</span>
<span class="sd">  set of candidate subnetworks that attempt to minimize the loss function</span>
<span class="sd">  defined in Equation (4) as part of an ensemble. At the end of each iteration,</span>
<span class="sd">  the best candidate is chosen based on its ensemble&#39;s complexity-regularized</span>
<span class="sd">  train loss. New subnetworks are allowed to use any subnetwork weights within</span>
<span class="sd">  the previous iteration&#39;s ensemble in order to improve upon them. If the</span>
<span class="sd">  complexity-regularized loss of the new ensemble, as defined in Equation (4),</span>
<span class="sd">  is less than that of the previous iteration&#39;s ensemble, the AdaNet algorithm</span>
<span class="sd">  continues onto the next iteration.</span>

<span class="sd">  AdaNet attempts to minimize the following loss function to learn the mixture</span>
<span class="sd">  weights &#39;w&#39; of each subnetwork &#39;h&#39; in the ensemble with differentiable</span>
<span class="sd">  convex non-increasing surrogate loss function Phi:</span>

<span class="sd">  Equation (4):</span>

<span class="sd">    F(w) = 1/m * sum_{i = 1 to m}(Phi(1 - y_i * sum_{j = 1 to N}(w_j * h_j)))</span>
<span class="sd">           + sum_{j = 1 to N}(Gamma_j * |w_j|)</span>

<span class="sd">    where Gamma_j = lambda * r_j + beta, with lambda &gt;= 0 and beta &gt;= 0.</span>

<span class="sd">  This implementation uses an `adanet.subnetwork.Generator` as its weak learning</span>
<span class="sd">  algorithm for generating candidate subnetworks. These are trained in parallel</span>
<span class="sd">  using a single graph per iteration. At the end of each iteration, the</span>
<span class="sd">  estimator saves the sub-graph of the best subnetwork ensemble and its weights</span>
<span class="sd">  as a separate checkpoint. At the beginning of the next iteration, the</span>
<span class="sd">  estimator imports the previous iteration&#39;s frozen graph and adds ops for the</span>
<span class="sd">  next candidates as part of a new graph and session. This allows the estimator</span>
<span class="sd">  have the performance of Tensorflow&#39;s static graph constraint (minus the</span>
<span class="sd">  performance hit of reconstructing a graph between iterations), while having</span>
<span class="sd">  the flexibility of having a dynamic graph.</span>

<span class="sd">  NOTE: Subclassing `tf.estimator.Estimator` is only necessary to work with</span>
<span class="sd">  `tf.estimator.train_and_evaluate` which asserts that the estimator argument is</span>
<span class="sd">  a `tf.estimator.Estimator` subclass. However, all training is delegated to a</span>
<span class="sd">  separate `tf.estimator.Estimator` instance. It is responsible for supporting</span>
<span class="sd">  both local and distributed training. As such, the AdaNet `Estimator` is only</span>
<span class="sd">  responsible for bookkeeping across iterations.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">class</span> <span class="nc">_Keys</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="n">CURRENT_ITERATION</span> <span class="o">=</span> <span class="s2">&quot;current_iteration&quot;</span>
    <span class="n">EVALUATE_ENSEMBLES</span> <span class="o">=</span> <span class="s2">&quot;evaluate_ensembles&quot;</span>
    <span class="n">MATERIALIZE_REPORT</span> <span class="o">=</span> <span class="s2">&quot;materialize_report&quot;</span>
    <span class="n">INCREMENT_ITERATION</span> <span class="o">=</span> <span class="s2">&quot;increment_iteration&quot;</span>
    <span class="n">PREVIOUS_ENSEMBLE_ARCHITECTURE</span> <span class="o">=</span> <span class="s2">&quot;previous_ensemble_architecture&quot;</span>
    <span class="n">SUBNETWORK_GENERATOR</span> <span class="o">=</span> <span class="s2">&quot;subnetwork_generator&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">head</span><span class="p">,</span>
               <span class="n">subnetwork_generator</span><span class="p">,</span>
               <span class="n">max_iteration_steps</span><span class="p">,</span>
               <span class="n">mixture_weight_type</span><span class="o">=</span><span class="n">MixtureWeightType</span><span class="o">.</span><span class="n">SCALAR</span><span class="p">,</span>
               <span class="n">mixture_weight_initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">warm_start_mixture_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">adanet_lambda</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
               <span class="n">adanet_beta</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
               <span class="n">evaluator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">report_materializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">metric_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">force_grow</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">replicate_ensemble_in_training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">adanet_loss_decay</span><span class="o">=.</span><span class="mi">9</span><span class="p">,</span>
               <span class="n">worker_wait_timeout_secs</span><span class="o">=</span><span class="mi">7200</span><span class="p">,</span>
               <span class="n">model_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">report_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Initializes an `Estimator`.</span>

<span class="sd">    Args:</span>
<span class="sd">      head: A `tf.contrib.estimator.Head` instance for computing loss and</span>
<span class="sd">        evaluation metrics for every candidate.</span>
<span class="sd">      subnetwork_generator: The `adanet.subnetwork.Generator` which defines the</span>
<span class="sd">        candidate subnetworks to train and evaluate at every AdaNet iteration.</span>
<span class="sd">      max_iteration_steps: Total number of steps for which to train candidates</span>
<span class="sd">        per iteration. If `OutOfRange` or `StopIteration` occurs in the middle,</span>
<span class="sd">        training stops before `max_iteration_steps` steps.</span>
<span class="sd">      mixture_weight_type: The `adanet.MixtureWeightType` defining which mixture</span>
<span class="sd">        weight type to learn in the linear combination of subnetwork outputs.</span>
<span class="sd">        * `SCALAR`: creates a rank 0 tensor mixture weight . It performs an</span>
<span class="sd">          element- wise multiplication with its subnetwork&#39;s logits. This</span>
<span class="sd">          mixture weight is the simplest to learn, the quickest to train, and</span>
<span class="sd">          most likely to generalize well.</span>
<span class="sd">        * `VECTOR`:  creates a tensor with shape [k] where k is the ensemble&#39;s</span>
<span class="sd">          logits dimension as defined by `head`. It is similar to `SCALAR` in</span>
<span class="sd">          that it performs an element-wise multiplication with its subnetwork&#39;s</span>
<span class="sd">          logits, but is more flexible in learning a subnetworks&#39;s preferences</span>
<span class="sd">          per class.</span>
<span class="sd">        * `MATRIX`: creates a tensor of shape [a, b] where a is the number of</span>
<span class="sd">          outputs from the subnetwork&#39;s `last_layer` and b is the number of</span>
<span class="sd">          outputs from the ensemble&#39;s `logits`. This weight matrix-multiplies</span>
<span class="sd">          the subnetwork&#39;s `last_layer`. This mixture weight offers the most</span>
<span class="sd">          flexibility and expressivity, allowing subnetworks to have outputs of</span>
<span class="sd">          different dimensionalities. However, it also has the most trainable</span>
<span class="sd">          parameters (a*b), and is therefore the most sensitive to learning</span>
<span class="sd">          rates and regularization.</span>
<span class="sd">      mixture_weight_initializer: The initializer for mixture_weights. When</span>
<span class="sd">        `None`, the default is different according to `mixture_weight_type`:</span>
<span class="sd">        * `SCALAR`: initializes to 1/N where N is the number of subnetworks in</span>
<span class="sd">          the ensemble giving a uniform average.</span>
<span class="sd">        * `VECTOR`: initializes each entry to 1/N where N is the number of</span>
<span class="sd">          subnetworks in the ensemble giving a uniform average.</span>
<span class="sd">        * `MATRIX`: uses `tf.zeros_initializer`.</span>
<span class="sd">      warm_start_mixture_weights: Whether, at the beginning of an iteration, to</span>
<span class="sd">        initialize the mixture weights of the subnetworks from the previous</span>
<span class="sd">        ensemble to their learned value at the previous iteration, as opposed to</span>
<span class="sd">        retraining them from scratch. Takes precedence over the value for</span>
<span class="sd">        `mixture_weight_initializer` for subnetworks from previous iterations.</span>
<span class="sd">      adanet_lambda: Float multiplier &#39;lambda&#39; for applying L1 regularization to</span>
<span class="sd">        subnetworks&#39; mixture weights &#39;w&#39; in the ensemble proportional to their</span>
<span class="sd">        complexity. See Equation (4) in the AdaNet paper.</span>
<span class="sd">      adanet_beta: Float L1 regularization multiplier &#39;beta&#39; to apply equally to</span>
<span class="sd">        all subnetworks&#39; weights &#39;w&#39; in the ensemble regardless of their</span>
<span class="sd">        complexity. See Equation (4) in the AdaNet paper.</span>
<span class="sd">      evaluator: An `Evaluator` for candidate selection after all subnetworks</span>
<span class="sd">        are done training. When `None`, candidate selection uses a moving</span>
<span class="sd">        average of their `Ensemble`&#39;s AdaNet loss during training instead. In</span>
<span class="sd">        order to use the *AdaNet algorithm* as described in [Cortes et al.,</span>
<span class="sd">        &#39;17], the given `Evaluator` must be created with the same dataset</span>
<span class="sd">        partition used during training. Otherwise, this framework will perform</span>
<span class="sd">        *AdaNet.HoldOut* which uses a holdout set for candidate selection, but</span>
<span class="sd">        does not benefit from learning guarantees.</span>
<span class="sd">      report_materializer: A `ReportMaterializer` for materializing a</span>
<span class="sd">        `Builder`&#39;s `subnetwork.Reports` into `subnetwork.MaterializedReport`s.</span>
<span class="sd">        These reports are made available to the Generator at the next iteration,</span>
<span class="sd">        so that it can adapt its search space. When `None`, the Generators&#39;</span>
<span class="sd">        `generate_candidates` method will receive empty Lists for their</span>
<span class="sd">        `previous_ensemble_reports` and `all_reports` arguments.</span>
<span class="sd">      use_bias: Whether to add a bias term to the ensemble&#39;s logits. Adding a</span>
<span class="sd">        bias allows the ensemble to learn a shift in the data, often leading to</span>
<span class="sd">        more stable training and better predictions.</span>
<span class="sd">      metric_fn: A function which should obey the following signature:</span>
<span class="sd">        - Args: can only have following three arguments in any order:</span>
<span class="sd">          * predictions: Predictions `Tensor` or dict of `Tensor` created by</span>
<span class="sd">            given `head`.</span>
<span class="sd">          * features: Input `dict` of `Tensor` objects created by `input_fn`</span>
<span class="sd">            which is given to `estimator.evaluate` as an argument.</span>
<span class="sd">          * labels:  Labels `Tensor` or dict of `Tensor` (for multi-head)</span>
<span class="sd">            created by `input_fn` which is given to `estimator.evaluate` as an</span>
<span class="sd">            argument.</span>
<span class="sd">        - Returns: Dict of metric results keyed by name. Final metrics are a</span>
<span class="sd">          union of this and `head&#39;s` existing metrics. If there is a name</span>
<span class="sd">          conflict between this and `head`s existing metrics, this will override</span>
<span class="sd">          the existing one. The values of the dict are the results of calling a</span>
<span class="sd">          metric function, namely a `(metric_tensor, update_op)` tuple.</span>
<span class="sd">      force_grow: Boolean override that forces the ensemble to grow by one</span>
<span class="sd">        subnetwork at the end of each iteration. Normally at the end of each</span>
<span class="sd">        iteration, AdaNet selects the best candidate ensemble according to its</span>
<span class="sd">        performance on the AdaNet objective. In some cases, the best ensemble is</span>
<span class="sd">        the `previous_ensemble` as opposed to one that includes a newly trained</span>
<span class="sd">        subnetwork. When `True`, the algorithm will not select the</span>
<span class="sd">        `previous_ensemble` as the best candidate, and will ensure that after n</span>
<span class="sd">        iterations the final ensemble is composed of n subnetworks.</span>
<span class="sd">      replicate_ensemble_in_training: Whether to rebuild the frozen subnetworks</span>
<span class="sd">        of the ensemble in training mode, which can change the outputs of the</span>
<span class="sd">        frozen subnetworks in the ensemble. When `False` and during candidate</span>
<span class="sd">        training, the frozen subnetworks in the ensemble are in prediction mode,</span>
<span class="sd">        so training-only ops like dropout are not applied to them. When `True`</span>
<span class="sd">        and training the candidates, the frozen subnetworks will be in training</span>
<span class="sd">        mode as well, so they will apply training-only ops like dropout.  This</span>
<span class="sd">        argument is useful for regularizing learning mixture weights, or for</span>
<span class="sd">        making training-only side inputs available in subsequent iterations. For</span>
<span class="sd">        most use-cases, this should be `False`.</span>
<span class="sd">      adanet_loss_decay: Float decay for the exponential-moving-average of the</span>
<span class="sd">        AdaNet objective throughout training. This moving average is a data-</span>
<span class="sd">        driven way tracking the best candidate with only the training set.</span>
<span class="sd">      worker_wait_timeout_secs: Float number of seconds for workers to wait for</span>
<span class="sd">        chief to prepare the next iteration during distributed training. This is</span>
<span class="sd">        needed to prevent workers waiting indefinitely for a chief that may have</span>
<span class="sd">        crashed or been turned down. When the timeout is exceeded, the worker</span>
<span class="sd">        exits the train loop. In situations where the chief job is much slower</span>
<span class="sd">        than the worker jobs, this timeout should be increased.</span>
<span class="sd">      model_dir: Directory to save model parameters, graph and etc. This can</span>
<span class="sd">        also be used to load checkpoints from the directory into a estimator to</span>
<span class="sd">        continue training a previously saved model.</span>
<span class="sd">      report_dir: Directory where the `adanet.subnetwork.MaterializedReport`s</span>
<span class="sd">        materialized by `report_materializer` would be saved. If</span>
<span class="sd">        `report_materializer` is None, this will not save anything. If `None` or</span>
<span class="sd">        empty string, defaults to &quot;&lt;model_dir&gt;/report&quot;.</span>
<span class="sd">      config: `RunConfig` object to configure the runtime settings.</span>
<span class="sd">      **kwargs: Extra keyword args passed to the parent.</span>

<span class="sd">    Returns:</span>
<span class="sd">      An `Estimator` instance.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If `subnetwork_generator` is `None`.</span>
<span class="sd">      ValueError: If `max_iteration_steps` is &lt;= 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># TODO: Add argument to specify how many frozen graph</span>
    <span class="c1"># checkpoints to keep.</span>

    <span class="k">if</span> <span class="n">subnetwork_generator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;subnetwork_generator can&#39;t be None.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_iteration_steps</span> <span class="o">&lt;=</span> <span class="mf">0.</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;max_iteration_steps must be &gt; 0.&quot;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_subnetwork_generator</span> <span class="o">=</span> <span class="n">subnetwork_generator</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_adanet_loss_decay</span> <span class="o">=</span> <span class="n">adanet_loss_decay</span>

    <span class="c1"># Overwrite superclass&#39;s assert that members are not overwritten in order</span>
    <span class="c1"># to overwrite public methods. Note that we are doing something that is not</span>
    <span class="c1"># explicitly supported by the Estimator API and may break in the future.</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">Estimator</span><span class="o">.</span><span class="n">_assert_members_are_not_overridden</span> <span class="o">=</span> <span class="nb">staticmethod</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_checkpoint_path</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_evaluator</span> <span class="o">=</span> <span class="n">evaluator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_report_materializer</span> <span class="o">=</span> <span class="n">report_materializer</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_force_grow</span> <span class="o">=</span> <span class="n">force_grow</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_worker_wait_timeout_secs</span> <span class="o">=</span> <span class="n">worker_wait_timeout_secs</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_name</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_inside_adanet_training_loop</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># This `Estimator` is responsible for bookkeeping across iterations, and</span>
    <span class="c1"># for training the subnetworks in both a local and distributed setting.</span>
    <span class="c1"># Subclassing improves future-proofing against new private methods being</span>
    <span class="c1"># added to `tf.estimator.Estimator` that are expected to be callable by</span>
    <span class="c1"># external functions, such as in b/110435640.</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Estimator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_adanet_model_fn</span><span class="p">,</span>
        <span class="n">params</span><span class="o">=</span><span class="p">{},</span>
        <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
        <span class="n">model_dir</span><span class="o">=</span><span class="n">model_dir</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># These are defined after base Estimator&#39;s init so that they can</span>
    <span class="c1"># use the same temporary model_dir as the underlying Estimator even if</span>
    <span class="c1"># model_dir is not provided.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ensemble_builder</span> <span class="o">=</span> <span class="n">_EnsembleBuilder</span><span class="p">(</span>
        <span class="n">head</span><span class="o">=</span><span class="n">head</span><span class="p">,</span>
        <span class="n">mixture_weight_type</span><span class="o">=</span><span class="n">mixture_weight_type</span><span class="p">,</span>
        <span class="n">mixture_weight_initializer</span><span class="o">=</span><span class="n">mixture_weight_initializer</span><span class="p">,</span>
        <span class="n">warm_start_mixture_weights</span><span class="o">=</span><span class="n">warm_start_mixture_weights</span><span class="p">,</span>
        <span class="n">checkpoint_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_dir</span><span class="p">,</span>
        <span class="n">adanet_lambda</span><span class="o">=</span><span class="n">adanet_lambda</span><span class="p">,</span>
        <span class="n">adanet_beta</span><span class="o">=</span><span class="n">adanet_beta</span><span class="p">,</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">,</span>
        <span class="n">metric_fn</span><span class="o">=</span><span class="n">metric_fn</span><span class="p">)</span>
    <span class="n">candidate_builder</span> <span class="o">=</span> <span class="n">_CandidateBuilder</span><span class="p">(</span>
        <span class="n">max_steps</span><span class="o">=</span><span class="n">max_iteration_steps</span><span class="p">,</span>
        <span class="n">adanet_loss_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_adanet_loss_decay</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_iteration_builder</span> <span class="o">=</span> <span class="n">_IterationBuilder</span><span class="p">(</span><span class="n">candidate_builder</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">_ensemble_builder</span><span class="p">,</span>
                                                <span class="n">replicate_ensemble_in_training</span><span class="p">)</span>
    <span class="n">report_dir</span> <span class="o">=</span> <span class="n">report_dir</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_dir</span><span class="p">,</span> <span class="s2">&quot;report&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_report_accessor</span> <span class="o">=</span> <span class="n">_ReportAccessor</span><span class="p">(</span><span class="n">report_dir</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_latest_checkpoint_iteration_number</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the iteration number from the latest checkpoint.&quot;&quot;&quot;</span>

    <span class="n">latest_checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">latest_checkpoint</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">load_variable</span><span class="p">(</span><span class="n">latest_checkpoint</span><span class="p">,</span>
                                              <span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">CURRENT_ITERATION</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_latest_checkpoint_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the iteration number from the latest checkpoint.&quot;&quot;&quot;</span>

    <span class="n">latest_checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">latest_checkpoint</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="s2">&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">load_variable</span><span class="p">(</span>
        <span class="n">latest_checkpoint</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">PREVIOUS_ENSEMBLE_ARCHITECTURE</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_latest_checkpoint_global_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the global step from the latest checkpoint.&quot;&quot;&quot;</span>

    <span class="n">latest_checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">latest_checkpoint</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">load_variable</span><span class="p">(</span><span class="n">latest_checkpoint</span><span class="p">,</span>
                                              <span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">GLOBAL_STEP</span><span class="p">)</span>

  <span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
  <span class="k">def</span> <span class="nf">_train_loop_context</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Tracks where the context is within the AdaNet train loop.&quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_inside_adanet_training_loop</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">yield</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_inside_adanet_training_loop</span> <span class="o">=</span> <span class="kc">False</span>

<div class="viewcode-block" id="Estimator.train"><a class="viewcode-back" href="../../../adanet.html#adanet.Estimator.train">[docs]</a>  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
            <span class="n">input_fn</span><span class="p">,</span>
            <span class="n">hooks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">max_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">saving_listeners</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;See `tf.estimator.Estimator` train.&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">max_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Can not provide both steps and max_steps.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">steps</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must specify steps &gt; 0, given: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">max_steps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_latest_checkpoint_global_step</span><span class="p">()</span> <span class="o">+</span> <span class="n">steps</span>

    <span class="c1"># Each iteration of this AdaNet loop represents an `_Iteration`. The</span>
    <span class="c1"># current iteration number is stored as a variable in the checkpoint so</span>
    <span class="c1"># that training can be stopped and started at anytime.</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_loop_context</span><span class="p">():</span>
      <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">current_iteration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_latest_checkpoint_iteration_number</span><span class="p">()</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Beginning training AdaNet iteration </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                        <span class="n">current_iteration</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iteration_ended</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">result</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">Estimator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
            <span class="n">input_fn</span><span class="o">=</span><span class="n">input_fn</span><span class="p">,</span>
            <span class="n">hooks</span><span class="o">=</span><span class="n">hooks</span><span class="p">,</span>
            <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
            <span class="n">saving_listeners</span><span class="o">=</span><span class="n">saving_listeners</span><span class="p">)</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Finished training Adanet iteration </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                        <span class="n">current_iteration</span><span class="p">)</span>

        <span class="c1"># If training ended because the maximum number of training steps</span>
        <span class="c1"># occurred, exit training.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_latest_checkpoint_global_step</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">max_steps</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>

        <span class="c1"># If training ended for any reason other than the iteration ending,</span>
        <span class="c1"># exit training.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iteration_ended</span><span class="p">:</span>
          <span class="k">return</span> <span class="n">result</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Beginning bookkeeping phase for iteration </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                        <span class="n">current_iteration</span><span class="p">)</span>

        <span class="c1"># The chief prepares the next AdaNet iteration, and increments the</span>
        <span class="c1"># iteration number by 1.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">is_chief</span><span class="p">:</span>
          <span class="c1"># As the chief, store the train hooks and make a placeholder input_fn</span>
          <span class="c1"># in order to use them when preparing the next iteration.</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_train_hooks</span> <span class="o">=</span> <span class="n">hooks</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_prepare_next_iteration</span><span class="p">(</span><span class="n">input_fn</span><span class="p">)</span>

        <span class="c1"># This inner loop serves mainly for synchronizing the workers with the</span>
        <span class="c1"># chief during distributed training. Workers that finish training early</span>
        <span class="c1"># wait for the chief to prepare the next iteration and increment the</span>
        <span class="c1"># iteration number. Workers that are slow to finish training quickly</span>
        <span class="c1"># move onto the next iteration. And workers that go offline and return</span>
        <span class="c1"># online after training ended terminate gracefully.</span>
        <span class="n">wait_for_chief</span> <span class="o">=</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">is_chief</span>
        <span class="n">timer</span> <span class="o">=</span> <span class="n">_CountDownTimer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_worker_wait_timeout_secs</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">wait_for_chief</span><span class="p">:</span>
          <span class="c1"># If the chief hits max_steps, it will stop training itself and not</span>
          <span class="c1"># increment the iteration number, so this is how the worker knows to</span>
          <span class="c1"># exit if it wakes up and the chief is gone.</span>
          <span class="c1"># TODO: Support steps parameter.</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_latest_checkpoint_global_step</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">max_steps</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>

          <span class="c1"># In distributed training, a worker may end training before the chief</span>
          <span class="c1"># overwrites the checkpoint with the incremented iteration number. If</span>
          <span class="c1"># that is the case, it should wait for the chief to do so. Otherwise</span>
          <span class="c1"># the worker will get stuck waiting for its weights to be initialized.</span>
          <span class="n">next_iteration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_latest_checkpoint_iteration_number</span><span class="p">()</span>
          <span class="k">if</span> <span class="n">next_iteration</span> <span class="o">&gt;</span> <span class="n">current_iteration</span><span class="p">:</span>
            <span class="k">break</span>

          <span class="c1"># Check timeout when waiting for potentially downed chief.</span>
          <span class="k">if</span> <span class="n">timer</span><span class="o">.</span><span class="n">secs_remaining</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="s2">&quot;Chief job did not prepare next iteration after </span><span class="si">%s</span><span class="s2"> secs. It &quot;</span>
                <span class="s2">&quot;may have been preempted, been turned down, or crashed. This &quot;</span>
                <span class="s2">&quot;worker is now exiting training.&quot;</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_worker_wait_timeout_secs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Waiting for chief to finish&quot;</span><span class="p">)</span>
          <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

        <span class="c1"># Stagger starting workers to prevent training instability.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">is_chief</span><span class="p">:</span>
          <span class="n">task_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">task_id</span> <span class="ow">or</span> <span class="mi">0</span>
          <span class="c1"># Wait 5 secs more for each new worker up to 60 secs.</span>
          <span class="n">delay_secs</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="n">task_id</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Waiting </span><span class="si">%d</span><span class="s2"> secs before starting training.&quot;</span><span class="p">,</span>
                          <span class="n">delay_secs</span><span class="p">)</span>
          <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">delay_secs</span><span class="p">)</span>

        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Finished bookkeeping phase for iteration </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                        <span class="n">current_iteration</span><span class="p">)</span></div>

<div class="viewcode-block" id="Estimator.evaluate"><a class="viewcode-back" href="../../../adanet.html#adanet.Estimator.evaluate">[docs]</a>  <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">input_fn</span><span class="p">,</span>
               <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">hooks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">checkpoint_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;See `tf.estimator.Estimator` evaluate.&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">checkpoint_path</span><span class="p">:</span>
      <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>

    <span class="c1"># Ensure that the read to get the iteration number and read to restore</span>
    <span class="c1"># variable values come from the same checkpoint during evaluation.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_checkpoint_path</span> <span class="o">=</span> <span class="n">checkpoint_path</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_name</span> <span class="o">=</span> <span class="n">name</span>
    <span class="n">result</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">Estimator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
        <span class="n">input_fn</span><span class="p">,</span>
        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>
        <span class="n">hooks</span><span class="o">=</span><span class="n">hooks</span><span class="p">,</span>
        <span class="n">checkpoint_path</span><span class="o">=</span><span class="n">checkpoint_path</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_checkpoint_path</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">result</span></div>

  <span class="k">def</span> <span class="nf">_call_adanet_model_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_fn</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls model_fn with the given mode and parameters.&quot;&quot;&quot;</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">tf_random_seed</span><span class="p">)</span>
      <span class="c1"># Create global step before calling model_fn as does superclass.</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_or_create_global_step</span><span class="p">()</span>
      <span class="n">features</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">input_fn</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_adanet_model_fn</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_prepare_next_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_input_fn</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Prepares the next iteration.</span>

<span class="sd">    This method calls model_fn up to four times:</span>
<span class="sd">      1. To evaluate all candidate ensembles to find the best one.</span>
<span class="sd">      2. To materialize reports and store them to disk (if report_materializer</span>
<span class="sd">         exists).</span>
<span class="sd">      3. To overwrite the model directory&#39;s checkpoint with the next iteration&#39;s</span>
<span class="sd">         ops.</span>

<span class="sd">    Args:</span>
<span class="sd">      train_input_fn: The input_fn used during training.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># First, evaluate and choose the best ensemble for this iteration.</span>
    <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">params</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">EVALUATE_ENSEMBLES</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluator</span><span class="p">:</span>
      <span class="n">evaluator_input_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluator</span><span class="o">.</span><span class="n">input_fn</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">evaluator_input_fn</span> <span class="o">=</span> <span class="n">train_input_fn</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_adanet_model_fn</span><span class="p">(</span><span class="n">evaluator_input_fn</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">EVAL</span><span class="p">,</span>
                               <span class="n">params</span><span class="p">)</span>

    <span class="c1"># Then materialize and store the subnetwork reports.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report_materializer</span><span class="p">:</span>
      <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
      <span class="n">params</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">MATERIALIZE_REPORT</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_adanet_model_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_report_materializer</span><span class="o">.</span><span class="n">input_fn</span><span class="p">,</span>
                                 <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">EVAL</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_best_ensemble_index</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Finally, create the graph for the next iteration and overwrite the model</span>
    <span class="c1"># directory checkpoint with the expanded graph.</span>
    <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">params</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">INCREMENT_ITERATION</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_adanet_model_fn</span><span class="p">(</span><span class="n">train_input_fn</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span>
                               <span class="n">params</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_architecture_filename</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteration_number</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the filename of the given iteration&#39;s frozen graph.&quot;&quot;&quot;</span>

    <span class="n">frozen_checkpoint</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">,</span> <span class="s2">&quot;architecture&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">-</span><span class="si">{}</span><span class="s2">.txt&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">frozen_checkpoint</span><span class="p">,</span> <span class="n">iteration_number</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_overwrite_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteration_number_tensor</span><span class="p">,</span> <span class="n">iteration_number</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Overwrites the latest checkpoint with the current graph.</span>

<span class="sd">    This is necessary for two reasons:</span>
<span class="sd">     1. To add variables to the checkpoint that were newly created for the</span>
<span class="sd">     next iteration. Otherwise Estimator will raise an exception for having a</span>
<span class="sd">     checkpoint missing variables.</span>
<span class="sd">     2. To increment the current iteration number so that workers know when to</span>
<span class="sd">     begin training the next iteration.</span>

<span class="sd">    Args:</span>
<span class="sd">      iteration_number_tensor: Int variable `Tensor` storing the current</span>
<span class="sd">        iteration number.</span>
<span class="sd">      iteration_number: Int number of the current iteration.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">checkpoint_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_checkpoint_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
    <span class="n">latest_checkpoint</span> <span class="o">=</span> <span class="n">checkpoint_state</span><span class="o">.</span><span class="n">model_checkpoint_path</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">latest_checkpoint</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="c1"># Run train hook &#39;begin&#39; methods which can add ops to the graph, so that</span>
    <span class="c1"># they are still present in the overwritten checkpoint.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_hooks</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_hooks</span><span class="p">:</span>
        <span class="n">hook</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span>

    <span class="n">global_step_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_global_step</span><span class="p">()</span>
    <span class="n">global_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">load_variable</span><span class="p">(</span><span class="n">latest_checkpoint</span><span class="p">,</span>
                                                     <span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">GLOBAL_STEP</span><span class="p">)</span>

    <span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">,</span> <span class="s2">&quot;increment.ckpt&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">master</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">(),</span>
                      <span class="n">tf</span><span class="o">.</span><span class="n">local_variables_initializer</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">tables_initializer</span><span class="p">())</span>
      <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
      <span class="n">coord</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Coordinator</span><span class="p">()</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">start_queue_runners</span><span class="p">(</span><span class="n">sess</span><span class="o">=</span><span class="n">sess</span><span class="p">,</span> <span class="n">coord</span><span class="o">=</span><span class="n">coord</span><span class="p">)</span>
      <span class="n">control_deps</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">global_step_tensor</span><span class="p">,</span> <span class="n">global_step</span><span class="p">),</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">iteration_number_tensor</span><span class="p">,</span> <span class="n">iteration_number</span><span class="p">),</span>
      <span class="p">]</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">control_deps</span><span class="p">):</span>
        <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span>
            <span class="n">sharded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">keep_checkpoint_max</span><span class="p">)</span>
        <span class="n">saver</span><span class="o">.</span><span class="n">recover_last_checkpoints</span><span class="p">(</span>
            <span class="n">checkpoint_state</span><span class="o">.</span><span class="n">all_model_checkpoint_paths</span><span class="p">)</span>
        <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">iteration_number</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_hooks</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_hooks</span><span class="p">:</span>
          <span class="n">hook</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_get_best_ensemble_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">current_iteration</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the best candidate ensemble&#39;s index in this iteration.</span>

<span class="sd">    Evaluates the ensembles using an `Evaluator` when provided. Otherwise,</span>
<span class="sd">    it returns the index of the best candidate as defined by the `_Iteration`.</span>

<span class="sd">    Args:</span>
<span class="sd">      current_iteration: Current `_Iteration`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Index of the best ensemble in the iteration&#39;s list of `_Candidates`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Skip the evaluation phase when there is only one candidate subnetwork.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
          <span class="s2">&quot;As the only candidate, &#39;</span><span class="si">%s</span><span class="s2">&#39; is moving onto the next iteration.&quot;</span><span class="p">,</span>
          <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ensemble_spec</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="k">return</span> <span class="mi">0</span>

    <span class="c1"># The zero-th index candidate at iteration t&gt;0 is always the</span>
    <span class="c1"># previous_ensemble.</span>
    <span class="k">if</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">number</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_force_grow</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span>
        <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">):</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
          <span class="s2">&quot;As the only candidate with `force_grow` enabled, &#39;</span><span class="si">%s</span><span class="s2">&#39; is moving&quot;</span>
          <span class="s2">&quot;onto the next iteration.&quot;</span><span class="p">,</span>
          <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ensemble_spec</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="k">return</span> <span class="mi">1</span>

    <span class="n">latest_checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting ensemble evaluation for iteration </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">current_iteration</span><span class="o">.</span><span class="n">number</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">(),</span>
                      <span class="n">tf</span><span class="o">.</span><span class="n">local_variables_initializer</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">tables_initializer</span><span class="p">())</span>
      <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
      <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="n">sharded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">latest_checkpoint</span><span class="p">)</span>
      <span class="n">coord</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Coordinator</span><span class="p">()</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">start_queue_runners</span><span class="p">(</span><span class="n">sess</span><span class="o">=</span><span class="n">sess</span><span class="p">,</span> <span class="n">coord</span><span class="o">=</span><span class="n">coord</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluator</span><span class="p">:</span>
        <span class="n">adanet_losses</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">c</span><span class="o">.</span><span class="n">ensemble_spec</span><span class="o">.</span><span class="n">adanet_loss</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span>
        <span class="p">]</span>
        <span class="n">adanet_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluator</span><span class="o">.</span><span class="n">evaluate_adanet_losses</span><span class="p">(</span>
            <span class="n">sess</span><span class="p">,</span> <span class="n">adanet_losses</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">adanet_losses</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
            <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">adanet_loss</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">])</span>
      <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">)):</span>
        <span class="n">metric_name</span> <span class="o">=</span> <span class="s2">&quot;adanet_loss&quot;</span>
        <span class="n">ensemble_name</span> <span class="o">=</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">ensemble_spec</span><span class="o">.</span><span class="n">name</span>
        <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">/</span><span class="si">{}</span><span class="s2"> = </span><span class="si">{:.6f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">ensemble_name</span><span class="p">,</span>
                                              <span class="n">adanet_losses</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Computed ensemble metrics: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">values</span><span class="p">))</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_force_grow</span> <span class="ow">and</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">number</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;The `force_grow` override is enabled, so the &quot;</span>
            <span class="s2">&quot;the performance of the previous ensemble will be ignored.&quot;</span><span class="p">)</span>
        <span class="c1"># NOTE: The zero-th index candidate at iteration t&gt;0 is always the</span>
        <span class="c1"># previous_ensemble.</span>
        <span class="n">adanet_losses</span> <span class="o">=</span> <span class="n">adanet_losses</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">adanet_losses</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">adanet_losses</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Finished ensemble evaluation for iteration </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">current_iteration</span><span class="o">.</span><span class="n">number</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;&#39;</span><span class="si">%s</span><span class="s2">&#39; at index </span><span class="si">%s</span><span class="s2"> is moving onto the next iteration&quot;</span><span class="p">,</span>
                    <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">ensemble_spec</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                    <span class="n">index</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">index</span>

  <span class="k">def</span> <span class="nf">_materialize_report</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">current_iteration</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generates reports as defined by `Builder`s.</span>

<span class="sd">    Materializes the Tensors and metrics defined in the `Builder`s&#39;</span>
<span class="sd">    `build_subnetwork_report` method using `ReportMaterializer`, and stores</span>
<span class="sd">    them to disk using `_ReportAccessor`.</span>

<span class="sd">    Args:</span>
<span class="sd">      current_iteration: Current `_Iteration`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">latest_checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Starting metric logging for iteration </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">current_iteration</span><span class="o">.</span><span class="n">number</span><span class="p">)</span>

    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_best_ensemble_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">best_candidate</span> <span class="o">=</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_best_ensemble_index</span><span class="p">]</span>
    <span class="n">best_ensemble</span> <span class="o">=</span> <span class="n">best_candidate</span><span class="o">.</span><span class="n">ensemble_spec</span><span class="o">.</span><span class="n">ensemble</span>
    <span class="n">best_name</span> <span class="o">=</span> <span class="n">best_ensemble</span><span class="o">.</span><span class="n">weighted_subnetworks</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
    <span class="n">included_subnetwork_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">best_name</span><span class="p">]</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
      <span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">(),</span>
                      <span class="n">tf</span><span class="o">.</span><span class="n">local_variables_initializer</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">tables_initializer</span><span class="p">())</span>
      <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
      <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="n">sharded</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">latest_checkpoint</span><span class="p">)</span>
      <span class="n">coord</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Coordinator</span><span class="p">()</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">start_queue_runners</span><span class="p">(</span><span class="n">sess</span><span class="o">=</span><span class="n">sess</span><span class="p">,</span> <span class="n">coord</span><span class="o">=</span><span class="n">coord</span><span class="p">)</span>
      <span class="n">materialized_reports</span> <span class="o">=</span> <span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_report_materializer</span><span class="o">.</span><span class="n">materialize_subnetwork_reports</span><span class="p">(</span>
              <span class="n">sess</span><span class="p">,</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">number</span><span class="p">,</span>
              <span class="n">current_iteration</span><span class="o">.</span><span class="n">subnetwork_reports</span><span class="p">,</span> <span class="n">included_subnetwork_names</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_report_accessor</span><span class="o">.</span><span class="n">write_iteration_report</span><span class="p">(</span><span class="n">current_iteration</span><span class="o">.</span><span class="n">number</span><span class="p">,</span>
                                                   <span class="n">materialized_reports</span><span class="p">)</span>

    <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Finished saving subnetwork reports for iteration </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">current_iteration</span><span class="o">.</span><span class="n">number</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_training_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">current_iteration</span><span class="p">,</span> <span class="n">training</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns training hooks for this iteration.</span>

<span class="sd">    Args:</span>
<span class="sd">      current_iteration: Current `_Iteration`.</span>
<span class="sd">      training: Whether in training mode.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of `tf.train.SessionRunHook` instances.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">after_fn</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_iteration_ended</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">training_hooks</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">_StopAfterTrainingHook</span><span class="p">(</span><span class="n">current_iteration</span><span class="p">,</span> <span class="n">after_fn</span><span class="o">=</span><span class="n">after_fn</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">summary</span> <span class="ow">in</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">summaries</span><span class="p">:</span>
      <span class="n">output_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span>
      <span class="k">if</span> <span class="n">summary</span><span class="o">.</span><span class="n">scope</span><span class="p">:</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">&quot;candidate&quot;</span><span class="p">,</span> <span class="n">summary</span><span class="o">.</span><span class="n">scope</span><span class="p">)</span>
      <span class="n">summary_saver_hook</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">SummarySaverHook</span><span class="p">(</span>
          <span class="n">save_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">save_summary_steps</span><span class="p">,</span>
          <span class="n">output_dir</span><span class="o">=</span><span class="n">output_dir</span><span class="p">,</span>
          <span class="n">summary_op</span><span class="o">=</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">())</span>
      <span class="n">training_hooks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">summary_saver_hook</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">training_hooks</span>

  <span class="k">def</span> <span class="nf">_evaluation_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">current_iteration</span><span class="p">,</span> <span class="n">training</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns evaluation hooks for this iteration.</span>

<span class="sd">    Args:</span>
<span class="sd">      current_iteration: Current `_Iteration`.</span>
<span class="sd">      training: Whether in training mode.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of `tf.train.SessionRunHook` instances.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">[]</span>
    <span class="n">evaluation_hooks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">:</span>
      <span class="n">eval_subdir</span> <span class="o">=</span> <span class="s2">&quot;eval&quot;</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_name</span><span class="p">:</span>
        <span class="n">eval_subdir</span> <span class="o">=</span> <span class="s2">&quot;eval_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_name</span><span class="p">)</span>
      <span class="n">eval_metric_hook</span> <span class="o">=</span> <span class="n">_EvalMetricSaverHook</span><span class="p">(</span>
          <span class="n">name</span><span class="o">=</span><span class="n">candidate</span><span class="o">.</span><span class="n">ensemble_spec</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
          <span class="n">eval_metric_ops</span><span class="o">=</span><span class="n">candidate</span><span class="o">.</span><span class="n">ensemble_spec</span><span class="o">.</span><span class="n">eval_metric_ops</span><span class="p">,</span>
          <span class="n">output_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">,</span> <span class="s2">&quot;candidate&quot;</span><span class="p">,</span>
                                  <span class="n">candidate</span><span class="o">.</span><span class="n">ensemble_spec</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">eval_subdir</span><span class="p">))</span>
      <span class="n">evaluation_hooks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eval_metric_hook</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">evaluation_hooks</span>

  <span class="k">def</span> <span class="nf">_save_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">ensemble</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Persists the ensemble&#39;s architecture in a serialized format.</span>

<span class="sd">    Writes to a text file with one subnetwork&#39;s iteration number and name</span>
<span class="sd">    per line.</span>

<span class="sd">    Args:</span>
<span class="sd">      filename: String filename to persist the ensemble architecture.</span>
<span class="sd">      ensemble: Target `adanet.Ensemble` instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">architecture</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">iteration_number</span><span class="p">,</span> <span class="n">w</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">weighted_subnetworks</span>
    <span class="p">]</span>
    <span class="c1"># Make directories since model_dir may not have been created yet.</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">MakeDirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">filename</span><span class="p">))</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">record_file</span><span class="p">:</span>
      <span class="n">record_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">linesep</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">architecture</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">_read_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Reads an ensemble architecture from disk.</span>

<span class="sd">    Assumes the file was written with `_save_architecture`.</span>

<span class="sd">    Args:</span>
<span class="sd">      filename: String filename where features were recorded.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of &lt;iteration_number&gt;:&lt;subnetwork name&gt; strings.</span>

<span class="sd">    Raises:</span>
<span class="sd">      OSError: When file not found at `filename`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">Exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">OSError</span><span class="p">(</span><span class="n">errno</span><span class="o">.</span><span class="n">ENOENT</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">strerror</span><span class="p">(</span><span class="n">errno</span><span class="o">.</span><span class="n">ENOENT</span><span class="p">),</span> <span class="n">filename</span><span class="p">)</span>

    <span class="n">architecture</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">record_file</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">record_file</span><span class="p">:</span>
        <span class="n">feature_name</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">rstrip</span><span class="p">()</span>
        <span class="n">architecture</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feature_name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">architecture</span>

  <span class="c1"># TODO: Refactor architecture building logic to its own module.</span>
  <span class="k">def</span> <span class="nf">_architecture_ensemble_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">architecture</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns an `_EnsembleSpec` with the given architecture.</span>

<span class="sd">    Creates the ensemble architecture by calling `generate_subnetworks` on</span>
<span class="sd">    `self._subnetwork_generator` and only calling `build_subnetwork` on</span>
<span class="sd">    `Builders` included in the architecture. Once their ops are created, their</span>
<span class="sd">    variables are restored from the checkpoint.</span>

<span class="sd">    Args:</span>
<span class="sd">      architecture: A list of &lt;iteration_number&gt;:&lt;subnetwork name&gt; strings.</span>
<span class="sd">      features: Dictionary of `Tensor` objects keyed by feature name.</span>
<span class="sd">      mode: Defines whether this is training, evaluation or prediction. See</span>
<span class="sd">        `ModeKeys`.</span>
<span class="sd">      labels: Labels `Tensor` or a dictionary of string label name to `Tensor`</span>
<span class="sd">        (for multi-head). Can be `None`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      An `EnsembleSpec` instance for the given architecture.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If a subnetwork from `architecture` is not found in the</span>
<span class="sd">        generated candidate `Builders` of the specified iteration.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">previous_ensemble_spec</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">previous_ensemble</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">serialized_subnetwork</span> <span class="ow">in</span> <span class="n">architecture</span><span class="p">:</span>
      <span class="n">serialized_iteration_number</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">serialized_subnetwork</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>
      <span class="n">rebuild_iteration_number</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">serialized_iteration_number</span><span class="p">)</span>
      <span class="n">previous_ensemble_reports</span><span class="p">,</span> <span class="n">all_reports</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report_materializer</span><span class="p">:</span>
        <span class="n">previous_ensemble_reports</span><span class="p">,</span> <span class="n">all_reports</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_collate_subnetwork_reports</span><span class="p">(</span><span class="n">rebuild_iteration_number</span><span class="p">))</span>
      <span class="n">generated_subnetwork_builders</span> <span class="o">=</span> <span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_subnetwork_generator</span><span class="o">.</span><span class="n">generate_candidates</span><span class="p">(</span>
              <span class="n">previous_ensemble</span><span class="o">=</span><span class="n">previous_ensemble</span><span class="p">,</span>
              <span class="n">iteration_number</span><span class="o">=</span><span class="n">rebuild_iteration_number</span><span class="p">,</span>
              <span class="n">previous_ensemble_reports</span><span class="o">=</span><span class="n">previous_ensemble_reports</span><span class="p">,</span>
              <span class="n">all_reports</span><span class="o">=</span><span class="n">all_reports</span><span class="p">))</span>
      <span class="n">rebuild_subnetwork_builder</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">for</span> <span class="n">builder</span> <span class="ow">in</span> <span class="n">generated_subnetwork_builders</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">builder</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
          <span class="n">rebuild_subnetwork_builder</span> <span class="o">=</span> <span class="n">builder</span>
          <span class="k">break</span>
      <span class="k">if</span> <span class="n">rebuild_subnetwork_builder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Required subnetwork name is missing from &quot;</span>
                         <span class="s2">&quot;generated candidates: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>

      <span class="n">previous_ensemble_summary</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="n">previous_ensemble_spec</span><span class="p">:</span>
        <span class="c1"># Always skip summaries when rebuilding previous architecture,</span>
        <span class="c1"># since they are not useful.</span>
        <span class="n">previous_ensemble_summary</span> <span class="o">=</span> <span class="n">_ScopedSummary</span><span class="p">(</span>
            <span class="n">previous_ensemble_spec</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">skip_summary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

      <span class="n">current_iteration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iteration_builder</span><span class="o">.</span><span class="n">build_iteration</span><span class="p">(</span>
          <span class="n">iteration_number</span><span class="o">=</span><span class="n">rebuild_iteration_number</span><span class="p">,</span>
          <span class="n">subnetwork_builders</span><span class="o">=</span><span class="p">[</span><span class="n">rebuild_subnetwork_builder</span><span class="p">],</span>
          <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
          <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
          <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
          <span class="n">previous_ensemble_summary</span><span class="o">=</span><span class="n">previous_ensemble_summary</span><span class="p">,</span>
          <span class="n">previous_ensemble_spec</span><span class="o">=</span><span class="n">previous_ensemble_spec</span><span class="p">,</span>
          <span class="n">rebuilding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">previous_ensemble_spec</span> <span class="o">=</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ensemble_spec</span>
      <span class="n">previous_ensemble</span> <span class="o">=</span> <span class="n">previous_ensemble_spec</span><span class="o">.</span><span class="n">ensemble</span>
    <span class="k">return</span> <span class="n">previous_ensemble_spec</span>

  <span class="k">def</span> <span class="nf">_collate_subnetwork_reports</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteration_number</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Prepares subnetwork.Reports to be passed to Generator.</span>

<span class="sd">    Reads subnetwork.MaterializedReports from past iterations,</span>
<span class="sd">    collates those that were included in previous_ensemble into</span>
<span class="sd">    previous_ensemble_reports as a List of subnetwork.MaterializedReports,</span>
<span class="sd">    and collates all reports from previous iterations into all_reports as</span>
<span class="sd">    another List of subnetwork.MaterializedReports.</span>

<span class="sd">    Args:</span>
<span class="sd">      iteration_number: Python integer AdaNet iteration number, starting from 0.</span>

<span class="sd">    Returns:</span>
<span class="sd">      (previous_ensemble_reports: List&lt;subnetwork.MaterializedReport&gt;,</span>
<span class="sd">       materialized_reports: List&lt;MaterializedReport&gt;)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">materialized_reports_all</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_report_accessor</span><span class="o">.</span><span class="n">read_iteration_reports</span><span class="p">())</span>
    <span class="n">previous_ensemble_reports</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_reports</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Since the number of iteration reports changes after the</span>
    <span class="c1"># MATERIALIZE_REPORT phase, we need to make sure that we always pass the</span>
    <span class="c1"># same reports to the Generator in the same iteration,</span>
    <span class="c1"># otherwise the graph that is built in the FREEZE_ENSEMBLE phase would be</span>
    <span class="c1"># different from the graph built in the training phase.</span>

    <span class="c1"># Iteration 0 should have 0 iteration reports passed to the</span>
    <span class="c1">#   Generator, since there are no previous iterations.</span>
    <span class="c1"># Iteration 1 should have 1 list of reports for Builders</span>
    <span class="c1">#   generated in iteration 0.</span>
    <span class="c1"># Iteration 2 should have 2 lists of reports -- one for iteration 0,</span>
    <span class="c1">#   one for iteration 1. Note that the list of reports for iteration &gt;= 1</span>
    <span class="c1">#   should contain &quot;previous_ensemble&quot;, in addition to the</span>
    <span class="c1">#   Builders at the start of that iteration.</span>
    <span class="c1"># Iteration t should have t lists of reports.</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">iteration_reports</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">materialized_reports_all</span><span class="p">):</span>

      <span class="c1"># This ensures that the FREEZE_ENSEMBLE phase does not pass the reports</span>
      <span class="c1"># generated in the previous phase of the same iteration to the</span>
      <span class="c1"># Generator when building the graph.</span>
      <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">iteration_number</span><span class="p">:</span>
        <span class="k">break</span>

      <span class="c1"># Assumes that only one subnetwork is added to the ensemble in</span>
      <span class="c1"># each iteration.</span>
      <span class="n">chosen_subnetwork_in_this_iteration</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">subnetwork_report</span> <span class="k">for</span> <span class="n">subnetwork_report</span> <span class="ow">in</span> <span class="n">iteration_reports</span>
          <span class="k">if</span> <span class="n">subnetwork_report</span><span class="o">.</span><span class="n">included_in_final_ensemble</span>
      <span class="p">][</span><span class="mi">0</span><span class="p">]</span>
      <span class="n">previous_ensemble_reports</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chosen_subnetwork_in_this_iteration</span><span class="p">)</span>

      <span class="n">all_reports</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">iteration_reports</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">previous_ensemble_reports</span><span class="p">,</span> <span class="n">all_reports</span>

  <span class="k">def</span> <span class="nf">_adanet_model_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;AdaNet model_fn.</span>

<span class="sd">    This model_fn is called at least three times per iteration:</span>
<span class="sd">     1. The first call generates, builds, and trains the candidate subnetworks</span>
<span class="sd">     to ensemble in this iteration.</span>
<span class="sd">     2. Once training is over, bookkeeping begins. The next call is to evaluate</span>
<span class="sd">     the best candidate ensembles according to the AdaNet objective.</span>
<span class="sd">     2.b. Optionally, when a report materializer is provided, another call</span>
<span class="sd">     creates the graph for producing subnetwork reports for the next iteration</span>
<span class="sd">     and other AdaNet runs.</span>
<span class="sd">     3. The final call is responsible for rebuilding the ensemble architecture</span>
<span class="sd">     from t-1 by regenerating the best builders and warm-starting their weights,</span>
<span class="sd">     adding ops and initialing the weights for the next candidate subnetworks,</span>
<span class="sd">     and overwriting the latest checkpoint with its graph and variables, so that</span>
<span class="sd">     first call of the next iteration has the right variables in the checkpoint.</span>

<span class="sd">    Args:</span>
<span class="sd">      features: Dictionary of `Tensor` objects keyed by feature name.</span>
<span class="sd">      labels: Labels `Tensor` or a dictionary of string label name to `Tensor`</span>
<span class="sd">        (for multi-head). Can be `None`.</span>
<span class="sd">      mode: Defines whether this is training, evaluation or prediction. See</span>
<span class="sd">        `ModeKeys`.</span>
<span class="sd">      params: A dict of parameters.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A `EstimatorSpec` instance.</span>

<span class="sd">    Raises:</span>
<span class="sd">      UserWarning: When calling model_fn directly in TRAIN mode.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">training</span> <span class="o">=</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span>
    <span class="k">if</span> <span class="n">training</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inside_adanet_training_loop</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">UserWarning</span><span class="p">(</span>
          <span class="s2">&quot;The adanet.Estimator&#39;s model_fn should not be called directly in &quot;</span>
          <span class="s2">&quot;TRAIN mode, because its behavior is undefined outside the context &quot;</span>
          <span class="s2">&quot;of its `train` method. If you are trying to add custom metrics &quot;</span>
          <span class="s2">&quot;with `tf.contrib.estimator.add_metrics`, pass the `metric_fn` to &quot;</span>
          <span class="s2">&quot;this `Estimator&#39;s` constructor instead.&quot;</span><span class="p">)</span>

    <span class="n">iteration_number</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_latest_checkpoint_iteration_number</span><span class="p">()</span>

    <span class="c1"># Use the evaluation checkpoint path to get both the iteration number and</span>
    <span class="c1"># variable values to avoid any race conditions between the first and second</span>
    <span class="c1"># checkpoint reads.</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">EVAL</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_checkpoint_path</span><span class="p">:</span>
      <span class="n">iteration_number</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">load_variable</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_checkpoint_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">CURRENT_ITERATION</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">INCREMENT_ITERATION</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
      <span class="n">iteration_number</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">architecture_filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_filename</span><span class="p">(</span><span class="n">iteration_number</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">architecture</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">Exists</span><span class="p">(</span><span class="n">architecture_filename</span><span class="p">):</span>
      <span class="n">architecture</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_architecture</span><span class="p">(</span><span class="n">architecture_filename</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
          <span class="s2">&quot;Importing architecture from </span><span class="si">%s</span><span class="s2">: [</span><span class="si">%s</span><span class="s2">].&quot;</span><span class="p">,</span> <span class="n">architecture_filename</span><span class="p">,</span>
          <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">([</span><span class="s2">&quot;&#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">architecture</span><span class="p">])))</span>

    <span class="n">skip_summaries</span> <span class="o">=</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;adanet&quot;</span><span class="p">):</span>
      <span class="n">previous_ensemble_spec</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">previous_ensemble</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">previous_ensemble_summary</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="n">architecture</span><span class="p">:</span>
        <span class="n">previous_ensemble_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_ensemble_spec</span><span class="p">(</span>
            <span class="n">architecture</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">previous_ensemble</span> <span class="o">=</span> <span class="n">previous_ensemble_spec</span><span class="o">.</span><span class="n">ensemble</span>
        <span class="n">previous_ensemble_summary</span> <span class="o">=</span> <span class="n">_ScopedSummary</span><span class="p">(</span>
            <span class="n">previous_ensemble_spec</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">skip_summary</span><span class="o">=</span><span class="n">skip_summaries</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">INCREMENT_ITERATION</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
        <span class="n">latest_checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">warm_start</span><span class="p">(</span><span class="n">latest_checkpoint</span><span class="p">,</span> <span class="n">vars_to_warm_start</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;.*&quot;</span><span class="p">])</span>
      <span class="n">previous_ensemble_reports</span><span class="p">,</span> <span class="n">all_reports</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_report_materializer</span><span class="p">:</span>
        <span class="n">previous_ensemble_reports</span><span class="p">,</span> <span class="n">all_reports</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_collate_subnetwork_reports</span><span class="p">(</span><span class="n">iteration_number</span><span class="p">))</span>
      <span class="n">subnetwork_builders</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_subnetwork_generator</span><span class="o">.</span><span class="n">generate_candidates</span><span class="p">(</span>
          <span class="n">previous_ensemble</span><span class="o">=</span><span class="n">previous_ensemble</span><span class="p">,</span>
          <span class="n">iteration_number</span><span class="o">=</span><span class="n">iteration_number</span><span class="p">,</span>
          <span class="n">previous_ensemble_reports</span><span class="o">=</span><span class="n">previous_ensemble_reports</span><span class="p">,</span>
          <span class="n">all_reports</span><span class="o">=</span><span class="n">all_reports</span><span class="p">)</span>
      <span class="n">current_iteration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iteration_builder</span><span class="o">.</span><span class="n">build_iteration</span><span class="p">(</span>
          <span class="n">iteration_number</span><span class="o">=</span><span class="n">iteration_number</span><span class="p">,</span>
          <span class="n">subnetwork_builders</span><span class="o">=</span><span class="n">subnetwork_builders</span><span class="p">,</span>
          <span class="n">features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
          <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
          <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
          <span class="n">previous_ensemble_summary</span><span class="o">=</span><span class="n">previous_ensemble_summary</span><span class="p">,</span>
          <span class="n">previous_ensemble_spec</span><span class="o">=</span><span class="n">previous_ensemble_spec</span><span class="p">)</span>

    <span class="c1"># Variable which allows us to read the current iteration from a checkpoint.</span>
    <span class="n">iteration_number_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">CURRENT_ITERATION</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span>
        <span class="n">initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">(),</span>
        <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">adanet_summary</span> <span class="o">=</span> <span class="n">_ScopedSummary</span><span class="p">(</span><span class="s2">&quot;global&quot;</span><span class="p">,</span> <span class="n">skip_summaries</span><span class="p">)</span>
    <span class="n">adanet_summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;iteration/adanet/iteration&quot;</span><span class="p">,</span> <span class="n">iteration_number_tensor</span><span class="p">)</span>
    <span class="n">adanet_summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;iteration_step/adanet/iteration_step&quot;</span><span class="p">,</span>
                          <span class="n">current_iteration</span><span class="o">.</span><span class="n">step</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">estimator_spec</span><span class="o">.</span><span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">adanet_summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">estimator_spec</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>
      <span class="n">adanet_summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">&quot;loss/adanet/adanet_weighted_ensemble&quot;</span><span class="p">,</span>
                            <span class="n">current_iteration</span><span class="o">.</span><span class="n">estimator_spec</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>

    <span class="n">iteration_estimator_spec</span> <span class="o">=</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">estimator_spec</span>
    <span class="n">estimator_spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">EstimatorSpec</span><span class="p">(</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
        <span class="n">predictions</span><span class="o">=</span><span class="n">iteration_estimator_spec</span><span class="o">.</span><span class="n">predictions</span><span class="p">,</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">iteration_estimator_spec</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
        <span class="n">train_op</span><span class="o">=</span><span class="n">iteration_estimator_spec</span><span class="o">.</span><span class="n">train_op</span><span class="p">,</span>
        <span class="n">eval_metric_ops</span><span class="o">=</span><span class="n">iteration_estimator_spec</span><span class="o">.</span><span class="n">eval_metric_ops</span><span class="p">,</span>
        <span class="n">training_hooks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_training_hooks</span><span class="p">(</span><span class="n">current_iteration</span><span class="p">,</span> <span class="n">training</span><span class="p">),</span>
        <span class="n">evaluation_hooks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_evaluation_hooks</span><span class="p">(</span><span class="n">current_iteration</span><span class="p">,</span> <span class="n">training</span><span class="p">),</span>
        <span class="n">scaffold</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Scaffold</span><span class="p">(</span><span class="n">summary_op</span><span class="o">=</span><span class="n">adanet_summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()),</span>
        <span class="n">export_outputs</span><span class="o">=</span><span class="n">iteration_estimator_spec</span><span class="o">.</span><span class="n">export_outputs</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">EVALUATE_ENSEMBLES</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
      <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">is_chief</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_best_ensemble_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_best_ensemble_index</span><span class="p">(</span>
          <span class="n">current_iteration</span><span class="p">)</span>
      <span class="n">ensemble</span> <span class="o">=</span> <span class="n">current_iteration</span><span class="o">.</span><span class="n">candidates</span><span class="p">[</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_best_ensemble_index</span><span class="p">]</span><span class="o">.</span><span class="n">ensemble_spec</span><span class="o">.</span><span class="n">ensemble</span>
      <span class="n">new_architecture_filename</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_architecture_filename</span><span class="p">(</span><span class="n">iteration_number</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_save_architecture</span><span class="p">(</span><span class="n">new_architecture_filename</span><span class="p">,</span> <span class="n">ensemble</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">MATERIALIZE_REPORT</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
      <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">is_chief</span>
      <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_best_ensemble_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_materialize_report</span><span class="p">(</span><span class="n">current_iteration</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_Keys</span><span class="o">.</span><span class="n">INCREMENT_ITERATION</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
      <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">is_chief</span>
      <span class="n">latest_checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
          <span class="s2">&quot;Overwriting checkpoint with new graph for iteration </span><span class="si">%s</span><span class="s2"> to </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
          <span class="n">iteration_number</span><span class="p">,</span> <span class="n">latest_checkpoint</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_overwrite_checkpoint</span><span class="p">(</span><span class="n">iteration_number_tensor</span><span class="p">,</span> <span class="n">iteration_number</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">estimator_spec</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Charles Weill and Javier Gonzalvo

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
    

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>